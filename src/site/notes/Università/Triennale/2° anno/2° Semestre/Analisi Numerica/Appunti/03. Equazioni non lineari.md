---
{"dg-publish":true,"permalink":"/universita/triennale/2-anno/2-semestre/analisi-numerica/appunti/03-equazioni-non-lineari/"}
---


pdf:: [[3. Equazioni non lineari - ANEP - Pitolli.pdf]]

L'analisi numerica è la scienza degli errori
Approssimare soluzioni equazione non lineare

# 3. I metodi numerici

```ad-Definizione
title: Calcolo Numerico
Il **calcolo numerico** è quella branca della matematica che *costruisce* e *analizza* i metodi numerici atti a risolvere, con l'aiuto del calcolatore, differenti problemi matematici che nascono da varie discipline.

```


```ad-example
title: Esempio: Serbatoio sferico


Immaginiamo di voler progettare un **serbatoio sferico** per la raccolta d'acqua da installare in un piccolo villaggio in una regione arida

Il primo passo è la [[#Schematizzazione]] sulla base di ipotesi esemplificative. Questo dà origine ai cosiddetti [[#Errori inerenti]].

Si passa quindi alla formulazione di un [[#Modello matematico]]. Nel nostro caso consiste nella formula per calcolare il *volume del liquido* noto il raggio $R$ del serbatoio e l'altezza $h$ dell'acqua al suo interno.

Sia il serbatoio di raggio $3 \, \mathrm{m}$, a quale altezza bisogna riempirlo per avere a disposizione acqua sufficiente per il fabbisogno minimo di un mese per 20 persone?

#### Dati
- Raggio $R = 3 \, \mathrm{m}$ 
- Periodo $T = 30 \, \mathrm{giorni}$ 
- Persone $N = 20$

#### Dati stimati
- Consumo minimo $C = 50 \, \mathrm{l}$ a persona 
- Litri d'acqua $L = 50 \cdot 30 \cdot 20 \, \mathrm{l} = 30.000 \, \mathrm{l}$ 
- Volume dell'acqua $V = 30 \, \mathrm{m^{3}}$ 

#### Modello matematico

![Schermata 2023-03-06 alle 17.55.06.png|300](/img/user/Universit%C3%A0/Triennale/2%C2%B0%20anno/2%C2%B0%20Semestre/Analisi%20Numerica/Appunti/allegati/Schermata%202023-03-06%20alle%2017.55.06.png)

Sappiamo che il volume del liquido contenuto nel serbatoio può essere calcolato dalla formula:

$
V(h)  = \pi h^{2} \frac{3R-h}{3}
$
dove $h$ è l'altezza in metri dell'acqua nel serbatoio

#### Soluzione

Voglio trovare l'altezza $h$ per cui $V(h) = 30$. Devo risolvere l'equazione non lineare:

$
V(h)  = \pi h^{2} \frac{3R-h}{3} \iff 
f(h) = \pi h^{3} - 9 \pi h^{2} + 90 = 0
$

![Schermata 2023-03-06 alle 17.57.50.png](/img/user/Universit%C3%A0/Triennale/2%C2%B0%20anno/2%C2%B0%20Semestre/Analisi%20Numerica/Appunti/allegati/Schermata%202023-03-06%20alle%2017.57.50.png)



```




1. Problema
2. Schematizzare
3. Tradurre in linguaggio matematico --> Errori inerenti
4. Modello matematico
5. Metodo Numerico --> Errore di troncamento
6. Algoritmo --> Stabilità
7. Soluzione numerica --> Errori di arrotondamento (il calcolatore lavora con un numero limitato di cifre significative)


## Risoluzione di un problema con i metodi numerici

### Descrizione del problema fisico
Si comincia dalla descrizione del problema. 
Si registrano le misure fornite, azioni (forze) in gioco. Si fanno le dovute approssimazioni. 

### Traduzione del problema in linguaggio matematico
Il problema fisico deve essere tradotto in equazioni matematiche. Una volta fatto ciò avremo a disposizione un [[#Modello matematico]]. 

#### Modello matematico

Alcuni esempi di modelli matematici nella [[#Traduzione del problema in linguaggio matematico]] sono:
- Sistemi di equazioni non lineari (equilibri chimici, ottimizzazione)
- Integrali (aree, volumi, energia)
- Sistemi di equazioni differenziali

Quando si costruisce un modello matematico si compiono alcuni errori detti [[#Errori inerenti]].

##### Errori inerenti
Gli errori inerenti sono gli errori che si commettono nella costruzione di un [[#Modello matematico]].


### Metodo numerico
Una volta definito il modello si passa all'utilizzo di un metodo analitico (se possibile) o un **metodo numerico** per trovarne la soluzione. 
Quando si usano i metodi numerici si devono costruire degli [[#Algoritmo|algoritmi]] compiono [[#Errori di troncamento]]

#### Intervallo di separazione
Il primo passo da seguire è quello di isolare la soluzione del problema che si vuole risolvere.

```ad-Definizione
title: Intervallo di Separazione $I$

L'**Intervallo di Separazione** è un intervallo in cui abbiamo individuato un'unica soluzione del problema. 


$
I = [a, b] \ \text{t.c.}\ \exists ! \xi \in I
$

dove $\xi$ è soluzione esatta del problema. 
```

#### Errori di troncamento
Gli errori di troncamento sono gli errori che si compiono nell'applicazione di un [[#Metodo numerico]]. Ad esempio, se applico il metodo di bisezione l'errore di troncamento è quello che compio per essermi fermato dopo 5 iterazioni piuttosto che un numero maggiore. 

#### Algoritmo

Applicare un [[#Metodo numerico]] significa scrivere un algoritmo che possa essere reiterato un numero finito di volte per arrivare sempre più vicino al risultato reale del problema. Quando si costruisce un algoritmo è bene assicurarsi che sia **stabile**. È infatti possibile che il risultato esploda dopo un certo numero di reiterazioni.

### Soluzione numerica

Dopo aver applicato il [[#Metodo numerico]] si arriva finalmente alla soluzione numerica al problema. 
È importante a questo punto interpretare il risultato e assicurarsi che la soluzione abbia senso (non possiamo avere ad esempio masse negative). 
In questa fase si deve inoltre fare attenzione a un'ulteriore causa di errore: gli [[#Errori di arrotondamento]]

#### Errori di arrotondamento

I calcolatori lavorano con un numero finito di cifre significative. Quando rappresentano un numero con molte cifre (ad esempio $\pi$) per i calcoli compieranno degli errori dovuti al fatto che non sono in grado di rappresentare il numero nella sua interezza. Questi tipi di errori si chiamano **errori di troncamento**.

L'arrotondamento è la prima fonte di **errore**. I dati di *input*, che hanno un numero infinito di cifre, vengono trasformati, tramite arrotondamento, in **numeri macchina**, con un numero finito di cifre.

```ad-example
title: Esempio: errore di arrotondamento


$
\begin{align}
q_{1}(x) &= (x-1)^{7} \\
q_{2}(x) &= x^{7} - 7x^{6} + 21x^{5} - 35x^{4} + 35x^{3} - 21x^{2} + 7x - 1
\end{align}
$

I polinomi $q_1(x)$ e $q_{2}(x)$ sono algebricamente identici.
Se però calcoliamo i loro valori numericamente nell'intervallo $[0.9998, 1.0002]$ usando 10 cifre significative:


| x      | $q_{1}(x)$ | $q_{2}(x)$ | Valore esatto | Errore di arrotondamento |
| ------ | ---------- | ---------- | ------------- | ------------------------ |
| 1      | 0          | 0          | 0             | 0                        |
| 1.0001 | $10^{-28}$ | $-10^{-10}$           |   $10^{-28}$            |   $-\simeq 10^{-10}$                       |


![Schermata 2023-03-06 alle 20.27.32.png](/img/user/Universit%C3%A0/Triennale/2%C2%B0%20anno/2%C2%B0%20Semestre/Analisi%20Numerica/Appunti/allegati/Schermata%202023-03-06%20alle%2020.27.32.png)


```

##### Cancellazione numerica

Un errore che si verifica quando calcoliamo la differenza di due numeri molto vicini.

## Algoritmo

```ad-Definizione
title: Algoritmo

Successione di istruzioni, finita e non ambigua, che consente di ottenere risultati numerici a partire dai dati di input.

Gli algoritmi vengono poi implementati in un linguaggio di programmazione.

```

### Stabilità di un algoritmo

Anche quando l'errore di arrotondamento è piccolo, la sua propagazione può avere effetti disastrosi. Essi possono infatti venire amplificati, rendendo in questo caso la soluzione del tutto inaffidabile. In questo caso si dice che l'algoritmo è **instabile**.

## Metodi numerici per la soluzione di problemi non lineari
Libro: 3.4

#### Metodo di bisezione

<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/universita/triennale/2-anno/2-semestre/analisi-numerica/appunti/03-1-metodo-di-bisezione/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">

<div class="markdown-embed-title">

# Il metodo di Bisezione

</div>



# 3.1 Il metodo di Bisezione

---

Il **metodo di bisezione** è un metodo numerico che consiste nel dimezzare di volta in volta l'[[Università/Triennale/2° anno/2° Semestre/Analisi Numerica/Appunti/03. Equazioni non lineari#Intervallo di separazione\|Intervallo di separazione]] e usare il punto medio di tale intervallo come approssimazione della soluzione $\xi$.
Consente di costruire una successione {$x_{k}$} di approssimazioni di $\xi$, ottenute assumendo $x_{k}$ come punto medio di un intervallo $[a_{k-1}, b_{k-1}]$ con $k \in \mathbb{N}^{+}$.
## ☑️ Ipotesi

```ad-tip
title: Ipotesi


1. $I = [a, b]$ [[01. Equazioni non lineari#Intervallo di separazione|Intervallo di separazione]]
2. $f(x) \in C^{0}[a,b]$
3. $f(a)\cdot f(b) < 0$


```

## Algoritmo

![GraficoMetodoBisezione 1.png](/img/user/Universit%C3%A0/Triennale/2%C2%B0%20anno/2%C2%B0%20Semestre/Analisi%20Numerica/Appunti/allegati/GraficoMetodoBisezione%201.png)

Individuato un[[Università/Triennale/2° anno/2° Semestre/Analisi Numerica/Appunti/01. Introduzione ai metodi numerici#Intervallo di separazione\|Intervallo di separazione]] $[a_{0}, b_{0}]$ ne calcolo il punto medio che chiamerò $x_{1}$:
$
x_{1} = \frac{b_{0} + a_{0}}{2}
$
Ora controllo in quale tra gli intervalli $[a_{0}, x_{1}]$ e $[x_{1}, b_{0}]$ appartiene la soluzione $\xi$, verificando che il prodotto $f(a_{k-1}) \cdot f(x_{k})$ oppure il prodotto $f(b_{k-1}) \cdot f(x_{k})$ sia negativo. 

Una volta individuato l'intervallo, ripeto il procedimento usando quello come nuovo intervallo di separazione. Supponiamo ad esempio che la soluzione cada nell'intervallo $[a_{0}, x_{1}]$, questo sarà proprio il nuovo intervallo di separazione $[a_{1}, b_{1}] = [a_{0}, x_{1}]$.

Chiamo $x_{2}$ il punto medio tra $a_{1}$ e $b_{1}$:
$
x_{2} = \frac{a_{1}+b_{1}}{2}
$
Continuando a ripetere questo processo, ammesso che il metodo [[#Convergenza|converga]], $x_{k}$ sarà man mano sempre più vicino alla soluzione $\xi$. 


- **Input**: $a = a_{0}, b=b_{0}$ per $k = 1,2,...$
	- $x_{k} = \frac{b_{k-1}-a_{k-1}}{2}$
- **se**:
	- $f(a_{k-1}) \cdot f(x_{k}) < 0 \Rightarrow [a_{k}, b_{k}] = [a_{k-1}, x_{k}]$
	- $f(b_{k-1}) \cdot f(x_{k}) < 0 \Rightarrow [a_{k}, b_{k}] = [x_{k}, b_{k-1}]$

## Errori
### Errore di troncamento


Nell'applicazione del metodo di bisezione, compiamo un [[Università/Triennale/2° anno/2° Semestre/Analisi Numerica/Appunti/01. Introduzione ai metodi numerici#Errore di troncamento\|Errore di troncamento]] dovuto quindi al numero di iterazioni che compiamo

## Convergenza

Calcolo l'errore $e_{k}$ tenendo presente che esso dovrà per forza essere minore della metà dell'ampiezza dell'intervallo.
A sua volta l'ampiezza dell'intervallo $[a_{k-1}, b_{k-1}]$ sarà la metà dell'intervallo della iterazione predente $[a_{k-2}, b_{k-2}]$ e così via

$
\begin{align}
|e_{k}| = |\xi - x_{k}|  \le & \frac{b_{k-1} - a_{k-1}}{2} \\

&\le \frac{1}{2}  \frac{b_{k-2}-a_{k-2}}{2} \\

 \vdots \\

&\le \frac{1}{2^{k}} (b_{0}- a_{0})

\end{align}
$
$
\Rightarrow |e_{k}| = |\xi - x_{k}| \le \frac{1}{2^{k}} (b_{0} - a_{0})
$
[[Università/Triennale/2° anno/2° Semestre/Analisi Numerica/Appunti/01. Introduzione ai metodi numerici#Convergenza\|Converge]]?
$
\lim_{k \to \infty} |e_{k}| = \lim_{k \to \infty} \left|\frac{1}{2^{k}}(b_{0}-a_{0}) \right| = 0
$
### Ordine di convergenza

```ad-Teo
title: Ordine di Convergenza

Il metodo di bisezione ha [[Università/Triennale/2° anno/2° Semestre/Analisi Numerica/Appunti/01. Introduzione ai metodi numerici#Ordine di convergenza\|ordine di convergenza]] pari a 1:
$
p = 1
$

___
**Dimostrazione:**

Ricordo che:
$
|e_{k+1}| = \frac{b_{k}-a_{k}}{2} = \frac{1}{2} \frac{b_{k-1}-a_{k-1}}{2} = \frac{b_{k-1}-a_{k-1}}{2^{2}}
$
e che:
$
|e_{k}| = \frac{b_{k-1}-a_{k-1}}{2}
$
per cui
$
\frac{|e_{k+1}|}{|e_{k}|^{p}} \approx \frac{b_{k-1}-a_{k-1}}{2^{2}} \cdot \frac{2}{b_{k-1}-a_{k-1}} = \frac{1}{2}
$
con $p=1$.



```


### Stima iterazioni necessarie

Per ottenere l'approssimazione della soluzione con una tolleranza scelta $\varepsilon$ sono necessarie almeno un certo numero $k$ di iterazioni. Questo numero può essere stimato a partire dalla relazione:

$
|e_{k}| = \frac{1}{2^{k}} (b-a) \le \varepsilon
$

Risolvendo per $k$ otteniamo infatti:

$
\begin{align}

2^{k} &\ge \frac{b-a}{\varepsilon} \\

log_{2}\left( 2^{k} \right) &\ge log_{2}\left( \frac{b-a}{\varepsilon} \right) \\

k &\ge log_{2}\left( \frac{b-a}{\varepsilon} \right)

\end{align}
$
Tenendo presente che $k$ deve per definizione essere un numero intero positivo.


## Criterio di arresto
### Criterio di arresto a posteriori

Posso interrompere l'algoritmo quando l'errore al passo k è minore di una tolleranza scelta $\varepsilon$.
$
|e_{k}| \le \varepsilon
$

## Implementazione in Matlab


```matlab
function [soluzioneApprox,erroreStimato, iterazioniNecessarie] = MetodoBisezioneNonLineari(estremoInferiore, estremoSuperiore, funzione, tolleranza, numeroMaxIterazioni)

% Questa funzione serve ad applicare il metodo di bisezione a una funzione
% assegnata per ricavarne la soluzione approssimata.
% Input:
% estermoInferiore, estremoSuperiore: Estremi dell'intervallo di separazione
% funzione: la funzione, definita come anonymous function, a cui
% applicare il metodo
% tolleranza: La tolleranza con la quale si vuole trovare la soluzione
% numeroMaxIterazioni: Il numero max di iterazioni che si vogliono
% provare prima di interrompere il calcolo. (Se non specificato è
% inizializzato a 100

% ------------

% Outpu:
% soluzioneApprox: la soluzione approssimata
% erroreStimato: la media degli errori calcolati come b-a e come f(xn)
% iterazioniNecessarie: Il numero di iterazioni necessarie alla stima
% dell'errore
% Cerco la radice di una funzione f nell'intervallo [a,b] con il metodo di
% bisezione
% Suppongo di aver già individuato gli estremi degli intervalli di
% separazione
% Sfrutteremo un criterio di arresto basato sulla tolleranza:
% f = Funzione della quale vogliamo cercare la radice
% a = Estremo inferiore in cui è stata isolata la radice
% b = Estremo superiore in cui è stata isolata la radice
% toll = Tolleranza (\tollilon)
% numeroMaxIterazioni = Massimo numero di iterazioni

f = funzione;

% So che nell'intervallo definito sotto sicuremante ci sarà una soluzione
a = estremoInferiore;
b = estremoSuperiore;

% Definisco la tolleranza
toll = tolleranza;
maxIter = 100;
maxIter = numeroMaxIterazioni;

% Vogliamo calcolare:
% xn: Approx della radice
% err1 = |x(n) - x(n-1)|
% err2 = f(xn)
% iter = Numero di iterazioni

format long

% Inizializzo i parametri necessari
iter = 0; err1 = b-a; err2 = toll+1; x0 = a;

% Verifico che la radice esista
if f(a)*f(b) > 0
	error('Non ci sono soluzioni nellintervallo [a,b]') % Con questo comando blocco l'esecuzione dello script
elseif f(a)*f(b) == 0
	if f(a) == 0
		xn = a;
	elseif f(b) == 0
		xn = b;
	end
	return % Return perché non voglio andare avanti se queste condizioni del secondo if sono rispettate
end

% Calcolo successione
while (err1 > toll) && iter < maxIter
	xn = (a+b)/2;
	if f(a)*f(xn) < 0
		b = xn;
	elseif f(xn)*f(b) < 0
		a = xn;
end

iter = iter + 1;
err1 = abs(xn-x0);
err2 = abs(f(xn));
x0 = xn;
end

soluzioneApprox = xn;
erroreStimato = abs((err1 + err2)/2);
iterazioniNecessarie = iter;

end

```




</div></div>




### Metodi iterativi a un punto
Si parla anche di **metodi delle approssimazioni successive** o dell'**iterazione funzionale**.

Un metodo di risoluzione consiste nel riformulare il problema dato riscrivendolo in una forma che sia più semplice da risolvere.
L'equazione
$$
f(x) = 0
$$

può infatti essere riscritta come

$$
x = \varphi (x)
$$

in un certo intervallo di separazione $I$.
Se $\xi$ è una radice esatta di $f$ per cui $f(\xi) = 0$, si ha che
$$
\xi = f(\xi)
$$
#### Equazione di punto unito

```ad-Definizione
title: Equazione di punto unito

Applicando questo metodo, il valore $x$ per cui 
$
x = \varphi (x)
$

è detto **punto unito** e l'equazione è detta **equazione di punto unito**.
```

Geometricamente, trovare il **punto unito** di $\varphi$ significa trovare l'intersezione tra le due rette:
$$
\begin{align}

y &= x \\
y &= \varphi(x)

\end{align}
$$
```ad-example
title: Es - Equazioni di punto unito

L'equazione
$
f(x) = x^{2} - x - 2 = 0
$
può essere riscritta in varie forme, tra cui:

$
\begin{matrix}

x = \varphi_{1}(x) = \sqrt{x+2} & x = \varphi_{2}(x) = - \sqrt{x+2} \\ 
x = \varphi_{3}(x) = x^{2}-2 & x = \varphi_{4}(x) = 1+ \frac{2}{x}


\end{matrix}
$

```

A questo punto si può scrivere la soluzione approssimata tramite un metodo iterativo a un punto:
$$
x_{n} = \varphi (x_{n-1})
$$
e l'obbiettivo è cercare la $x_{n}$ tale che:
$$
x_{n} = \varphi (x_{n})
$$
ossia proprio il [[#Equazione di punto unito|punto unito]].

#### Metodo Approssimazioni successive
Per approssimare un punto unito si può utilizzare il metodo delle approssimazioni successive: 
$$
\begin{cases}
x_{0} &\quad \text{Approssimazione iniziale} \\
x_{k} = \varphi(x_{k-1}) &\quad k = 1,2,...
\end{cases}
$$
La funzione $\varphi$ è detta di **iterazione**.

#### Convergenza per punto unito

```ad-Teo
title: Teorema

Definito l'[[#Errori di troncamento|errore di troncamento]] $e_{k}$, **se** il metodo converge, ossia

$
\lim_{k \to \infty} |e_{k}| = 0
$

che equivale a dire

$
\lim_{ k \to \infty } |\xi - x_{k}| = 0 \quad \iff \quad  \lim_{k \to \infty} x_{k} = \xi
$

**ALLORA**

$
\lim_{k \to \infty} x_{k} = \xi 
$
e 
$
\xi = \varphi(\xi)
$
dove $\xi$ è proprio il [[#Equazione di punto unito|punto unito]].

```

##### CN di convergenza per punto unito
```ad-Teo
title: Teo - Convergenza per punto unito
Se la successione
$
\begin{cases}
x_{0} &\quad \text{Approssimazione iniziale} \\
x_{k} = \varphi(x_{k-1}) &\quad k = 1,2,...
\end{cases}
$
è **Convergente** a un valore $\tau$ e $\varphi$ è **continua** in $\tau$ 
**allora** $\tau$ è [[#Equazione di punto unito|punto unito]] di $\varphi$, cioè $\tau = \varphi(\tau)$.

```

#### Criterio di arresto per punto unito
```ad-Teo
title: Teo - Criterio di arresto per punto unito

Se il metodo è convergente, una buona approssimazione di $\xi$ è data dal valore di $x_{k}$ per il quale
$
|x_{k} - x_{k-1}| \le \varepsilon
$
```



#### Alcuni metodi

I metodi seguenti sono esempi di metodi alle approssimazioni successive:

- [[#Metodo di Newton]]
- [[#Metodo delle secanti]]

#### Metodo di Newton


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/universita/triennale/2-anno/2-semestre/analisi-numerica/appunti/03-2-il-metodo-delle-tangenti/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">

<div class="markdown-embed-title">

# Metodo di Newton

</div>



# 3.2 Il metodo delle Tangenti

___

Il **metodo delle tangenti**, detto anche **metodo di Newton** sfrutta il [[Polinomio di Taylor\|Polinomio di Taylor]] per approssimare il valore delle funzioni. In questo caso è necessario scegliere un'approssimazione iniziale $x_{0}$.

Si tratta di fatto di un metodo di linearizzazione. Infatti, come vedremo, interromperemo il Polinomio di Taylor al primo ordine, confondendo quindi il valore della funzione con il valore della tangente.

![Metodo_delle_tangenti.png](/img/user/Universit%C3%A0/Triennale/2%C2%B0%20anno/2%C2%B0%20Semestre/Analisi%20Numerica/allegati/Metodo_delle_tangenti.png)

## ☑️ Ipotesi

Per l'applicabilità del metodo di newton, la funzione deve rispettare le seguenti ipotesi:

```ad-tip
title: Ipotesi 
1. $I$ è [[01. Introduzione ai metodi numerici#Intervallo di separazione|Intervallo di separazione]]
1. $f(x) \in \mathrm{C^{1}}(I = [a,b])$
2. $f'(x) \ne 0 \, \forall k$

```

## Algoritmo

Scelgo un'approssimazione iniziale $x_{0}$.

Approssimo la funzione $f(x)$ con un polinomio di Taylor al secondo ordine:
$
f(x) = f(x_{0}) + f'(x_{0})(x-x_{0}) + \frac{1}{2}f''(\tau)(x-x_{0})^{2} \text{ con } \tau \in [x_{0}, x]
$
Se cerco la radice di $f(x)$ impongo la funzione approssimata uguale a 0:
$
f(x) = f(x_{0}) + f'(x_{0})(x-x_{0}) \stackrel{!}{=} 0
$
da cui
$
x_{1} = x_{0} - \frac{f(x_{0})}{f'(x_{0})}
$
motivo per cui dobbiamo imporre anche $f'(x_{k}) \ne 0$ tra le [[#☑️ Ipotesi]].

Dopodiché approssimo nuovamente la funzione con Taylor usando stavolta $x_{1}$ al posto di $x_{0}$:
$
f(x) = f(x_{1}) + f'(x_{1})(x-x_{1}) \stackrel{!}{=} 0
$
da cui
$
x_{2} = x_{1} - \frac{f(x_{1})}{f'(x_{1})}
$
Continuo ad iterare questo procedimento. Avrò così, **in definitiva**:
$
x_{k} = x_{k-1} - \frac{f(x_{k-1})}{f'(x_{k-1})}
$
Il metodo [[#Convergenza|convergerà]] per alcuni valori di $x_{0} \in J \subset I$ (Ossia scegliendo $x_{0}$ *abbastanza vicino* a $\xi$).

```ad-important
title: Algoritmo

$
\begin{cases}
x_{0} \qquad \text{Punto iniziale}\\
x_{k} = x_{k-1} - \frac{f(x_{k-1})}{f'(x_{k-1})}
\end{cases}
$
```

## Convergenza

```ad-Teo
title: Condizione Necessaria di Convergenza
Sia $I = [a,b]$ un intervallo di separazione di uno zero di $f$;

Sia:

- $f \in C^{2}[a,b]$
- $f'(x) \ne 0$
- $x \in [a,b]$

**Allora** esiste un intorno $J$ di $\xi$, con $J \subset I$, tale che, se $x_{0} \in J$, la successione risulta convergente a $\xi$.

Inoltre, se $f\in C^{3}[a,b]$ l'[[01. Introduzione ai metodi numerici#Ordine di convergenza|ordine di convergenza]] è $\ge 2$.
```

___

```ad-Teo
title: Convergenza con Estremo di Fourier

Sia:

- $f \in C^{2}[a,b]$
- $f(a) \cdot f(b) < 0$
- $f''(x) \ne 0$

per $x \in [a,b]$, sia $x_{0}$ l'[[#Estremo di Fourier]] di $[a,b]$, **allora:**

1. Esiste un unico $\xi \in (a,b)$, tale che $f(\xi) = 0$
2. La successione $\{ \varphi(x_{n}) \}$ è monotona e converge a $\xi$
3. Se $f \in C^{3}[a,b]$, la convergenza è quadratica


```



### Estremo di Fourier

Se $f''(x) \ne 0 \,\,\,\,\, \forall x \in I$ si può dimostrare che si può scegliere uno dei due estremi di $I$ come approssimazione iniziale $x_{0}$.

Supponiamo di avere una funzione **monotona**, **senza massimi o minimi locali**, a **concavità fissa**.
L'**estremo di Fourier** di un intervallo è quello dei due tale che il prodotto $f(a)\cdot f''(a) > 0$ dove $a$ è l'estremo.


### Ordine di convergenza

```ad-Teo
title: Ordine di Convergenza per Tangenti
$p = 2$
```


Per calcolare l'[[01. Introduzione ai metodi numerici#Ordine di convergenza|ordine di convergenza]] devo calcolare il limite:
$
\lim_{k \to \infty} \frac{|e_{k+1}|}{|e_{k}|^{p}} = \text{C} > 0 \,\,\,\,\,\, p \ge 1
$
Calcolo $|e_{k+1}|$:

$
|e_{k+1}| = \xi - x_{k+1} = \left( \xi - \frac{f(\xi)}{f'(\xi)} \right) - x_{k+1}
$
essendo  $\frac{f(\xi)}{f'(\xi)} = 0$ perché $f(\xi) = 0$.

$
\begin{align}
|e_{k+1}| = \xi - x_{k+1} &= \left( \xi - \frac{f(\xi)}{f'(\xi)} \right) - x_{k+1} = \\

&= \left( \xi - \frac{f(\xi)}{f'(\xi)} \right) - \left( x_{k} - \frac{f(x_{k})}{f'(x_{k})} \right)  = \\

&= (\xi - x_{k}) - \left( \frac{f(\xi)}{f'(\xi)} - \frac{f(x_{k})}{f'(x_{k})} \right) = \\

\end{align}
$
Sviluppando $f(x_{k})$ e $f'(x_{k})$ in serie di Taylor e ricordando $\xi - x_{k} = e_{k}$ ottengo:

$
\begin{align}

|e_{k+1}| &= \left| 
e_{k} - \left( \frac{f(\xi)}{f'(\xi)} - \frac{f(\xi) + f'(\xi)(-e_{k}) + \frac{1}{2} f''(\xi)e_{k}^{2} }{f'(\xi)} \right)
\right| \\

&= \frac{1}{2} \left| \frac{f''(\xi)}{f'(\xi)} \right| |e_{k}^{2}|
\end{align}
$

Si ha quindi che 

$
\frac{|e_{k+1}|}{|e_{k}|^{p}} \stackrel{p = 2}{\approx} \frac{1}{2} \left| \frac{f''(\xi)}{f'(\xi)} \right|
$
quindi

$
\lim_{k \to \infty} \frac{|e_{k+1}|}{|e_{k}|^{2}} = \frac{1}{2} \left| \frac{f''(\xi)}{f'(\xi)} \right|
$
Allora **l'ordine di convergenza** del metodo delle tangenti è $p = 2$.

## Implementazione in Matlab

```matlab
function xk = tangenti(x0,f, df, N_max)

% Input:
%   x0: approx iniziale
%   f, df: funzione e derivata
%   N_max: numero di iterazioni
% 
% Output:
%   xk: approx dello zero

for i = 1:N_max
    xk = x0 - f(x0) / df(x0);
    errk = abs(xk - x0);
    x0 = xk;
    fprintf('k = %3i x_k = %14.12f err=%9.3e f=%18.12f f''=%18.12f \n', i, xk, errk, f(x0), df(x0));
end

end
```
# Metodo di Newton in $\mathbb{R}^n$

Al link [[Università/Triennale/2° anno/2° Semestre/Analisi Numerica/Appunti/03.4 Metodo di Newton in n dimensioni\|03.4 Metodo di Newton in n dimensioni]]

Se in $\mathbb{R}$ possiamo riscrivere una funzione sviluppandola in un Polinomio di Taylor, lo stesso possiamo fare con $\mathbb{R}^{n}$.

Sia $F(X): \mathbb{R}^{n} \to \mathbb{R}^{n}$, posso scrivere
$
F(X) = F(X^{(k)}) + J_{F}(X^{(k)})(X-X^{(k)}) + ...
$

dove 
$
\boldsymbol J_F(\boldsymbol X) = 
\begin{bmatrix} 

\frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \dots &\frac{\partial f_1}{\partial x_n}  \\ 

\frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \dots &\frac{\partial f_2}{\partial x_n}  \\ 

\vdots & \vdots & \ddots & \vdots \\ 

\frac{\partial f_n}{\partial x_1} & \frac{\partial f_n}{\partial x_2} & \dots &\frac{\partial f_n}{\partial x_n}  \\ 

\end{bmatrix}
$


</div></div>



#### Metodo delle secanti

<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/universita/triennale/2-anno/2-semestre/analisi-numerica/appunti/03-3-il-metodo-delle-secanti/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">

<div class="markdown-embed-title">

# Il metodo delle Secanti

</div>



# 3.3 Metodo delle Secanti
___

Il **metodo delle Secanti** consiste nell'approssimare localmente la funzione con la retta secante passante per i due estremi dell'intervallo $I$.

![Schermata 2024-10-23 alle 13.46.49.png](/img/user/Schermata%202024-10-23%20alle%2013.46.49.png)


## ☑️ Ipotesi

```ad-tip
title: Ipotesi 

1. $f(x) \in \mathrm{C}(I = [a,b])$
2. $f'(x_{k}) \ne 0 \, \forall k$
3. $f'(x) \ne 0 \,\,\,\, x \in I$ allora il metodo converge per $x_{0}, x_{1} \in J \subset I$
4. $f''(x) \ne 0 \,\,\,\, x\in I$ allora il metodo converge
```

## Algoritmo

Scelgo 2 **approssimazioni iniziali**: $x_{0}, x_{1}$
Poi, per $k = 2,3,...$ calcolo la soluzione approssimata come radice della retta secante passante per $x_{0}$ e $x_{1}$:
$
x_{k} = x_{k-1} - f(x_{k-1}) \frac{x_{k-1}-x_{k-2}}{f(x_{k-1})- f(x_{k-2})}
$

```ad-important
title: Algoritmo
$
\begin{cases}
x_{0}, x_{1} \qquad \text{Approssimazioni iniziali} \\
x_{k} = x_{k-1} - f(x_{k-1}) \frac{x_{k-1}-x_{k-2}}{f(x_{k-1})- f(x_{k-2})}
\end{cases}
$
```

## Convergenza

```ad-Teo
title: Prop - CS di Convergenza per Secanti
Se:
- $I = [a,b]$ intervallo di separazione, **simmetrico** intorno la radice $\xi$
- $f,f',f'' \in C^{2}[a,b]$
- $f'(x) \ne 0$ per $x \in [a,b]$

**Allora** esiste un intorno $J \subseteq I$ di $\xi$ tale che, se $x_{0}, x_{1} \in J$, la successione delle approssimazioni $\{x_{k}\}$ converge a $\xi$ con convergenza **superlineare**, cioè $1<p<2$.

In particolare, se $f''(x) \ne 0$ in $I$, l'[[#Ordine di convergenza]] è 
$
p = \frac{1+\sqrt{5}}{2}
$
```


### Ordine di convergenza

L'ordine di convergenza del metodo delle secanti è
$
p = \frac{1 + \sqrt{5}}{2} \approx 1.62
$
Essendo maggiore di 1 ma minore di 2 si dice che ha ordine di convergenza **sopralineare**.

## Implementazione in Matlab

```matlab
function [xk,errk, iter] = secanti_tol(x0,x1, f, N_max, tol)
% Input: (x0, x1, f, N_max, tol)
% x0, x1: Approx iniziali
%   f: Funzione di cui trovare gli zeri
%   N_max: Numero di iterazioni
%   tol: Tolleranza richiesta
%
% Output:
%   xk: approx dello zero
%   errk: Errore alla k-esima iterata
%   iter: Numero di iterazioni effettuate

errk  = tol + 1;
iter = 0;

while (iter < N_max) && (errk > tol)
    xk = x1 - f(x1)* (x1-x0) / (f(x1) - f(x0));
    errk = abs(xk-x1);
    x0 = x1;
    x1 = xk;
    iter = iter + 1;
end

fprintf('xk = %f', xk)
end


```




</div></div>


### Sistemi di equazioni NON lineari

I [[#Metodi iterativi a un punto]] permettono di risolvere anche sistemi di equazioni non lineari $n \times n$ del tipo:

$$
\begin{cases}

f_{1}(x_{1}, x_{2}, ..., x_{n}) &= 0 \\
f_{2}(x_{1}, x_{2}, ..., x_{n}) &= 0 \\
\vdots \\
f_{n}(x_{1}, x_{2}, ..., x_{n}) &= 0 \\

\end{cases}
$$

anche se le cose si complicano non poco.

È necessario per prima cosa riscrivere il sistema in forma matriciale.
Si ha infatti che il sistema è equivalente a:

$$
F(X) = 0
$$

dove 

$$
F: \mathbb{R}^{n} \to \mathbb{R}^{n}
$$
Esplicitando si ha che:

$$
F(X) = 
\begin{bmatrix}
f_{1} (x_{1}, x_{2}, ..., x_{n}) \\
f_{2} (x_{1}, x_{2}, ..., x_{n}) \\
\vdots \\ 
f_{3} (x_{1}, x_{2}, ..., x_{n}) \\
\end{bmatrix} 

=

\begin{bmatrix}
f_{1} (X) \\
f_{2} (X) \\
\vdots \\ 
f_{3} (X) \\
\end{bmatrix}
$$

con $X \in \mathbb{R}^{n}$:
$$
X =
\begin{bmatrix} 
x_{1} \\ x_{2} \\ \vdots  \\ x_{n}
\end{bmatrix}
$$
Sia $\overline X$ la soluzione esatta:
$$
\overline X =
\begin{bmatrix}
\xi_{1} \\ \xi_{2} \\ \vdots \\ \xi_{n}
\end{bmatrix}
$$
tale che $F(\overline X) = 0$.

Possiamo applicare il [[#Metodi iterativi a un punto|metodo del punto unito]] trasformando il sistema $F(X)= 0$:
$$
F(X) = 0 \iff X = \Phi(x)
$$
con
$$
\Phi: \mathbb{R}^{n} \to \mathbb{R}^{n} \text{ dove } \Phi(X) = 
\begin{bmatrix}

\varphi_{1}(X) \\ \varphi_{2}(X) \\ \vdots  \\ \varphi_{n}(X)

\end{bmatrix}
$$


Si può in questo modo applicare un metodo iterativo per cui:
$$
\begin{cases}

\boldsymbol{X^{(0)}} \in \mathbb{R}^{n} \\
\boldsymbol{X}^{(k+1)} = \boldsymbol{\Phi}(\boldsymbol{X^{(k)}}) && k = 0,1
\end{cases}
$$
Dove $\boldsymbol{X^{(0)}}$ è l'approssimazione iniziale data.

#### Errore di troncamento in $\mathbb{R}^n$

```ad-Definizione
title: Errore di troncamento in $\mathbb{R}^{n}$

$
E^{(k)} = \overline X - X^{(k)} \in \mathbb{R}^{n}
$

```

#### Convergenza in $\mathbb{R}^n$

```ad-Definizione
title: Convergenza in $\mathbb{R}^{n}$

Si dice che il metodo converge se

$
\lim_{k \to \infty} \text{dist}(\overline X, X^{(k)}) = 0
$

```

#### Distanza Euclidea

```ad-Definizione
title: Distanza Euclidea ($\text{dist}(V,W)$)

Dati due vettori: $V = \begin{bmatrix} v_{1} \\ \vdots \\ v_{n} \end{bmatrix}$ e $W = \begin{bmatrix} w_{1} \\ \vdots \\ w_{n} \end{bmatrix}$ la **distanza euclidea** tra $V$ e $W$ è:
$
\text{dist}(V,W) = \sqrt{ \sum\limits_{i=1}^{n}(v_{i}-w_{i})^{2} } = ||V-W||_{\text{Eu}}
$

```


#### Metodi per sistemi non lineari

##### Metodo di Newton in n dimensioni


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/universita/triennale/2-anno/2-semestre/analisi-numerica/appunti/03-4-metodo-di-newton-in-n-dimensioni/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">

<div class="markdown-embed-title">

# Metodo di Newton in n dimensioni

</div>




# Metodo di Newton in $\mathbb{R}^n$

Se in $\mathbb{R}$ possiamo riscrivere una funzione sviluppandola in un Polinomio di Taylor, lo stesso possiamo fare con $\mathbb{R}^{n}$.

Sia $F(X): \mathbb{R}^{n} \to \mathbb{R}^{n}$, posso scrivere
$
F(X) = F(X^{(k)}) + J_{F}(X^{(k)})(X-X^{(k)}) + ...
$

dove al posto della derivata, uso la matrice Jacobiana:
$
\boldsymbol J_{F}(\boldsymbol X) = 
\begin{bmatrix} 
\frac{\partial f_{1}}{\partial x_{1}} & \frac{\partial f_{1}}{\partial x_{2}} & \dots &\frac{\partial f_{1}}{\partial x_{n}}  \\ 
\frac{\partial f_{2}}{\partial x_{1}} & \frac{\partial f_{2}}{\partial x_{2}} & \dots &\frac{\partial f_{2}}{\partial x_{n}}  \\ 
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial f_{n}}{\partial x_{1}} & \frac{\partial f_{n}}{\partial x_{2}} & \dots &\frac{\partial f_{n}}{\partial x_{n}}  \\ 
\end{bmatrix}
$

Come metodo iterativo diventa l'equazione. La nuova approssimazione si trova risolvendo questo sistema

$
\boldsymbol F\left(\boldsymbol X^{(k)}\right) + \boldsymbol J_{F}(\boldsymbol X^{(k)}) \underbrace{(\boldsymbol X^{(k+1)}- \boldsymbol X^{(k)})}_{\stackrel{\triangle}{=}\boldsymbol{Y}^{(k+1)}} = 0
$
Ho ottenuto un problema lineare della forma:

$
\boldsymbol{J}_{F} (\boldsymbol{X}^{(k)}) \boldsymbol{Y}^{(k+1)} = - \boldsymbol{F}(\boldsymbol{X}^{(k)})
$

Posso quindi scrivere la soluzione approssimata $\boldsymbol{X}^{(k+1)}$ come:
$
\boldsymbol{X}^{(k+1)} = \boldsymbol{X}^{(k)}  + \boldsymbol{Y}^{(k+1)}
$
Se $\boldsymbol{J}_{F}(\boldsymbol{X}^{(k)})$ è invertibile, **allora** 
$
\boldsymbol{X}^{(k+1)} = \underbrace{\boldsymbol{X}^{(k)} - \left( J_{F} \left( \boldsymbol{X}^{(k)} \right) \right)^{-1} \boldsymbol{F} \left( X^{(k)} \right)}_{= \boldsymbol \Phi_{N} \left( \boldsymbol{X}^{(k)} \right) }
$
Mi fermo quando 
$
\mathrm{dist}\left( \boldsymbol{X}^{(k+1)}, \boldsymbol{X}^{(k)} \right) \le \varepsilon
$


</div></div>




# Risoluzione esercizi
- Cercare intervallo di separazione
	- Provare a scrivere nella forma $g(x) = h(x)$
	- Studiare monotonia di $g(x)$ e $h(x)$
	- Verificare l'esistenza di soluzioni in tutti gli intervalli a disposizione
	- Scrivere intervallo di separazione finale
- Verificare Condizioni di convergenza di uno dei metodi
- Stimare, se serve, il numero di iterazioni necessario con la formula del metodo di bisezione: $k \ge \log_{2}(\frac{b-a}{\varepsilon})$
- Applicare il metodo

